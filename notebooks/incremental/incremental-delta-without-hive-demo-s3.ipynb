{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18487f50-49e7-4c91-956e-08220158ebca",
   "metadata": {},
   "source": [
    "# POC: Incremental reads on Delta without hive metastore\n",
    "\n",
    "Using local metastore with incremental feactures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8536ac2e-33b5-40fd-9441-1d6a3b939206",
   "metadata": {},
   "source": [
    "# Use cases\n",
    "Change Data Feed is not enabled by default. The following use cases should drive when you enable the change data feed.\n",
    "\n",
    "1. Silver and Gold tables: Improve Delta performance by processing only row-level changes following initial MERGE, UPDATE, or DELETE operations to accelerate and simplify ETL and ELT operations.\n",
    "\n",
    "2. Transmit changes: Send a change data feed to downstream systems such as Kafka or RDBMS that can use it to incrementally process in later stages of data pipelines.\n",
    "\n",
    "3. Audit trail table: Capture the change data feed as a Delta table provides perpetual storage and efficient query capability to see all changes over time, including when deletes occur and what updates were made.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a208455e-e4a2-4b9a-9e6a-6fa25611dee7",
   "metadata": {},
   "source": [
    "# Known constrains:\n",
    "\n",
    "- The files in the _change_data folder follow the retention policy of the table. Therefore, if you run the VACUUM command, change data feed data is also deleted. Default is 7 days. [Reference](https://docs.delta.io/latest/delta-utility.html#remove-files-no-longer-referenced-by-a-delta-table)\n",
    "\n",
    "- With **column mapping** enabled on a Delta table, you can drop or rename columns in the table without rewriting data files for existing data. With column mapping enabled, change data feed has limitations after performing non-additive schema changes such as renaming or dropping a column, changing data type, or nullability changes. [Reference](https://docs.delta.io/latest/delta-change-data-feed.html#change-data-feed-limitations-for-tables-with-column-mapping-enabled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981d38af-6102-4418-ab9e-c3034de4d76d",
   "metadata": {},
   "source": [
    "## Before run\n",
    "\n",
    "Checks if spark 3.5.3 and Hadoop are install\n",
    "also the delta-spark>=3.2.1 and pyspark>=3.5.3 libraries.\n",
    "\n",
    "Ensure that minion s3 is running on port 9010 with user and password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91d07b1d-2be6-4b5d-bbbb-00270bba8367",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:40:39.814632Z",
     "iopub.status.busy": "2025-01-14T18:40:39.814327Z",
     "iopub.status.idle": "2025-01-14T18:40:39.867057Z",
     "shell.execute_reply": "2025-01-14T18:40:39.866753Z",
     "shell.execute_reply.started": "2025-01-14T18:40:39.814600Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, year, month, dayofmonth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40940756-17f4-44f7-ade4-8cc6a448538a",
   "metadata": {},
   "source": [
    "## Spark Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4d262d6-90c2-40f7-b4db-5ed3ec455956",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:40:39.867681Z",
     "iopub.status.busy": "2025-01-14T18:40:39.867522Z",
     "iopub.status.idle": "2025-01-14T18:40:39.870268Z",
     "shell.execute_reply": "2025-01-14T18:40:39.869854Z",
     "shell.execute_reply.started": "2025-01-14T18:40:39.867665Z"
    }
   },
   "outputs": [],
   "source": [
    "spark_jar_packages = \",\".join([\n",
    "    \"io.delta:delta-spark_2.12:3.2.0\",\n",
    "    \"org.apache.hadoop:hadoop-aws:3.3.4\",\n",
    "    \"com.amazonaws:aws-java-sdk-bundle:1.12.262\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e86afb24-b5e8-4469-9522-6bd3ead5b25a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:40:39.871432Z",
     "iopub.status.busy": "2025-01-14T18:40:39.871264Z",
     "iopub.status.idle": "2025-01-14T18:40:39.873863Z",
     "shell.execute_reply": "2025-01-14T18:40:39.873408Z",
     "shell.execute_reply.started": "2025-01-14T18:40:39.871416Z"
    }
   },
   "outputs": [],
   "source": [
    "LOCAL_WAREHOUSE_CATALOG = \"s3a://lakehouse-raw/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d417510-85ba-4981-a1c1-4b949381e70a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:40:39.874489Z",
     "iopub.status.busy": "2025-01-14T18:40:39.874283Z",
     "iopub.status.idle": "2025-01-14T18:40:42.852084Z",
     "shell.execute_reply": "2025-01-14T18:40:42.851679Z",
     "shell.execute_reply.started": "2025-01-14T18:40:39.874473Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/14 15:40:40 WARN Utils: Your hostname, baptvit resolves to a loopback address: 127.0.1.1; using 192.168.2.129 instead (on interface wlp4s0)\n",
      "25/01/14 15:40:40 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Ivy Default Cache set to: /home/baptvit/.ivy2/cache\n",
      "The jars for the packages stored in: /home/baptvit/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "com.amazonaws#aws-java-sdk-bundle added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-61015b4d-7c99-486d-b627-25294a7b06fc;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound io.delta#delta-spark_2.12;3.2.0 in central\n",
      "\tfound io.delta#delta-storage;3.2.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in local-m2-cache\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.4 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.12.262 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      ":: resolution report :: resolve 154ms :: artifacts dl 6ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.12.262 from central in [default]\n",
      "\tio.delta#delta-spark_2.12;3.2.0 from central in [default]\n",
      "\tio.delta#delta-storage;3.2.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from local-m2-cache in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.4 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   6   |   0   |   0   |   0   ||   6   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-61015b4d-7c99-486d-b627-25294a7b06fc\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 6 already retrieved (0kB/4ms)\n",
      "25/01/14 15:40:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/01/14 15:40:41 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/01/14 15:40:41 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 35956)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/socketserver.py\", line 318, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.12/socketserver.py\", line 349, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.12/socketserver.py\", line 362, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.12/socketserver.py\", line 761, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/baptvit/Documents/github/lakehouse-labs/.venv/lib/python3.12/site-packages/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/baptvit/Documents/github/lakehouse-labs/.venv/lib/python3.12/site-packages/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"/home/baptvit/Documents/github/lakehouse-labs/.venv/lib/python3.12/site-packages/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/baptvit/Documents/github/lakehouse-labs/.venv/lib/python3.12/site-packages/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"delta-without-playground\")\n",
    "    .config(\"spark.jars.packages\", spark_jar_packages)\n",
    "\n",
    "    # Delta Integration\n",
    "     .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "     .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "     \n",
    "    # Local\n",
    "    .config(\"spark.sql.catalog.local.type\", \"hadoop\")   # Use Hadoop catalog\n",
    "    .config(\"spark.sql.warehouse.dir\", LOCAL_WAREHOUSE_CATALOG)   # Path to store metadata\n",
    "    \n",
    "    # S3 (MinIO Integration)\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://localhost:9010\")\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\")\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\")\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\")\n",
    "    .config(\"spark.hadoop.fs.s3a.region\", \"us-east-1\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298217af-cd85-46d1-86e1-5b29ec517125",
   "metadata": {},
   "source": [
    "## Creating a fake database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59aaeae6-fc3a-4f76-aa2a-6a69b82b5e61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:40:44.746820Z",
     "iopub.status.busy": "2025-01-14T18:40:44.746558Z",
     "iopub.status.idle": "2025-01-14T18:40:44.800791Z",
     "shell.execute_reply": "2025-01-14T18:40:44.800434Z",
     "shell.execute_reply.started": "2025-01-14T18:40:44.746797Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9398e546-4d7b-4fa1-830b-3ce3b4f60802",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:40:44.902567Z",
     "iopub.status.busy": "2025-01-14T18:40:44.902376Z",
     "iopub.status.idle": "2025-01-14T18:40:44.905338Z",
     "shell.execute_reply": "2025-01-14T18:40:44.905076Z",
     "shell.execute_reply.started": "2025-01-14T18:40:44.902553Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_entry(faker: Faker, country_codes: list):\n",
    "    return {\n",
    "        \"id\": faker.unique.uuid4(),\n",
    "        \"name\":  faker.name(),\n",
    "        \"email\": faker.email(),\n",
    "        \"passport\": faker.passport_number(),\n",
    "        \"country_code\": random.choice(country_codes),\n",
    "        \"iban\": faker.iban(),\n",
    "        \"swift\": faker.swift11(),\n",
    "        \"created_at\": faker.past_date(start_date='-90d').strftime('%Y-%m-%d')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d45c96b0-71ee-4841-aa5c-3c2ab4f5429c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:40:45.082778Z",
     "iopub.status.busy": "2025-01-14T18:40:45.082429Z",
     "iopub.status.idle": "2025-01-14T18:40:45.085204Z",
     "shell.execute_reply": "2025-01-14T18:40:45.084823Z",
     "shell.execute_reply.started": "2025-01-14T18:40:45.082762Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_dataset(num: int, seed: int):\n",
    "    country_codes = ['US', 'CA', 'JP', 'KR', 'FR', 'GE', 'UK', 'BR', 'AR']\n",
    "    Faker.seed(seed)\n",
    "    faker = Faker()\n",
    "    return [generate_entry(faker, country_codes) for _ in range(num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3d6bf4c-4a93-4c83-b7bf-44bcc512fcd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:40:45.578486Z",
     "iopub.status.busy": "2025-01-14T18:40:45.578057Z",
     "iopub.status.idle": "2025-01-14T18:40:45.636409Z",
     "shell.execute_reply": "2025-01-14T18:40:45.636087Z",
     "shell.execute_reply.started": "2025-01-14T18:40:45.578467Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = generate_dataset(num=100, seed=739)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "796200e4-93af-4431-8a10-69447fe60695",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:40:46.118234Z",
     "iopub.status.busy": "2025-01-14T18:40:46.117916Z",
     "iopub.status.idle": "2025-01-14T18:40:47.402868Z",
     "shell.execute_reply": "2025-01-14T18:40:47.402476Z",
     "shell.execute_reply.started": "2025-01-14T18:40:46.118221Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/14 15:40:46 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(dataset)\\\n",
    "        .withColumn(\"year\", year(col(\"created_at\")))\\\n",
    "        .withColumn(\"month\", month(col(\"created_at\")))\\\n",
    "        .withColumn(\"day\", dayofmonth(col(\"created_at\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7239a48-2615-42af-83c9-72ce3135d7f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:40:47.403662Z",
     "iopub.status.busy": "2025-01-14T18:40:47.403521Z",
     "iopub.status.idle": "2025-01-14T18:40:48.705425Z",
     "shell.execute_reply": "2025-01-14T18:40:48.705075Z",
     "shell.execute_reply.started": "2025-01-14T18:40:47.403649Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df5c12af-1090-4a64-8b2d-2a2ec6e099dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:40:48.706008Z",
     "iopub.status.busy": "2025-01-14T18:40:48.705853Z",
     "iopub.status.idle": "2025-01-14T18:40:48.728999Z",
     "shell.execute_reply": "2025-01-14T18:40:48.728629Z",
     "shell.execute_reply.started": "2025-01-14T18:40:48.705989Z"
    }
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"accounts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59b96fc9-8459-447a-ac29-84431234056c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:40:50.010697Z",
     "iopub.status.busy": "2025-01-14T18:40:50.010418Z",
     "iopub.status.idle": "2025-01-14T18:40:50.639922Z",
     "shell.execute_reply": "2025-01-14T18:40:50.639451Z",
     "shell.execute_reply.started": "2025-01-14T18:40:50.010674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------\n",
      " country_code | BR                   \n",
      " created_at   | 2024-10-21           \n",
      " email        | powelljason@examp... \n",
      " iban         | GB77AKMZ560580635... \n",
      " id           | 5a424412-b127-4f8... \n",
      " name         | Cody Taylor          \n",
      " passport     | 895549199            \n",
      " swift        | INSEGB5PR6S          \n",
      " year         | 2024                 \n",
      " month        | 10                   \n",
      " day          | 21                   \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/14 15:40:57 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM accounts LIMIT 1;\").show(vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7892de8-a5d0-425a-b04d-84f19e2a0d2a",
   "metadata": {},
   "source": [
    "## Save using the default database\n",
    "\n",
    "Using the CDF Enable.\n",
    "delta.enableChangeDataFeed = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7509ab0-0562-4c53-b523-436487f62336",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:41:13.481208Z",
     "iopub.status.busy": "2025-01-14T18:41:13.480936Z",
     "iopub.status.idle": "2025-01-14T18:41:13.636884Z",
     "shell.execute_reply": "2025-01-14T18:41:13.636485Z",
     "shell.execute_reply.started": "2025-01-14T18:41:13.481187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    CREATE DATABASE IF NOT EXISTS delta\n",
    "    LOCATION 's3a://lakehouse-raw/delta/'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "658d39e9-69e4-41f6-aa29-6effce618c77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:41:16.965461Z",
     "iopub.status.busy": "2025-01-14T18:41:16.965180Z",
     "iopub.status.idle": "2025-01-14T18:41:19.781489Z",
     "shell.execute_reply": "2025-01-14T18:41:19.781113Z",
     "shell.execute_reply.started": "2025-01-14T18:41:16.965440Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 84,44% for 9 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 76,00% for 10 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 69,09% for 11 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 63,33% for 12 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 58,46% for 13 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 54,29% for 14 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 50,67% for 15 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 47,50% for 16 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 50,67% for 15 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 54,29% for 14 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 58,46% for 13 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 63,33% for 12 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 69,09% for 11 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 76,00% for 10 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 84,44% for 9 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 84,44% for 9 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 76,00% for 10 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 69,09% for 11 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 63,33% for 12 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 58,46% for 13 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 54,29% for 14 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 58,46% for 13 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 63,33% for 12 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 69,09% for 11 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 76,00% for 10 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 69,09% for 11 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 76,00% for 10 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 84,44% for 9 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 84,44% for 9 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 84,44% for 9 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 76,00% for 10 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 69,09% for 11 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 63,33% for 12 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 69,09% for 11 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 63,33% for 12 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 58,46% for 13 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 63,33% for 12 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 58,46% for 13 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 63,33% for 12 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 69,09% for 11 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 76,00% for 10 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 84,44% for 9 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "25/01/14 15:41:18 WARN MemoryManager: Total allocation exceeds 95,00% (1.020.054.720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .option(\"delta.enableChangeDataFeed\", \"true\") \\\n",
    "    .partitionBy(\"year\", \"month\") \\\n",
    "    .saveAsTable(\"delta.accounts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99b63d0-2322-4aea-a099-bb2c3a0597c0",
   "metadata": {},
   "source": [
    "## Reading from local direct from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79404a6d-3fda-4640-9a34-6ec814918545",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:41:31.278198Z",
     "iopub.status.busy": "2025-01-14T18:41:31.277356Z",
     "iopub.status.idle": "2025-01-14T18:41:31.281769Z",
     "shell.execute_reply": "2025-01-14T18:41:31.281255Z",
     "shell.execute_reply.started": "2025-01-14T18:41:31.278166Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3a://lakehouse-raw/delta/accounts'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOCAL_ACCOUNT_TABLE = LOCAL_WAREHOUSE_CATALOG + \"delta/accounts\"\n",
    "LOCAL_ACCOUNT_TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57c207a7-b228-4b50-953c-2fa48f71b036",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:41:33.571865Z",
     "iopub.status.busy": "2025-01-14T18:41:33.571572Z",
     "iopub.status.idle": "2025-01-14T18:41:33.678328Z",
     "shell.execute_reply": "2025-01-14T18:41:33.677982Z",
     "shell.execute_reply.started": "2025-01-14T18:41:33.571843Z"
    }
   },
   "outputs": [],
   "source": [
    "# providing a starting version\n",
    "df_read = spark.read.format(\"delta\") \\\n",
    "  .load(LOCAL_ACCOUNT_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24431a87-abcd-427d-a292-7ae05b4926d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:41:35.663086Z",
     "iopub.status.busy": "2025-01-14T18:41:35.662912Z",
     "iopub.status.idle": "2025-01-14T18:41:36.978515Z",
     "shell.execute_reply": "2025-01-14T18:41:36.978171Z",
     "shell.execute_reply.started": "2025-01-14T18:41:35.663075Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/14 15:41:35 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_read.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f952e84-15dc-4412-ac92-5f24bef256ff",
   "metadata": {},
   "source": [
    "## Reading the table history from local folder\n",
    "\n",
    "Local folder and spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e102addc-63ff-425e-883a-20c0fb9ec875",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:41:43.091256Z",
     "iopub.status.busy": "2025-01-14T18:41:43.090548Z",
     "iopub.status.idle": "2025-01-14T18:41:43.498060Z",
     "shell.execute_reply": "2025-01-14T18:41:43.497700Z",
     "shell.execute_reply.started": "2025-01-14T18:41:43.091222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " version             | 0                                                                                                                                               \n",
      " timestamp           | 2025-01-14 15:41:19                                                                                                                             \n",
      " userId              | NULL                                                                                                                                            \n",
      " userName            | NULL                                                                                                                                            \n",
      " operation           | CREATE OR REPLACE TABLE AS SELECT                                                                                                               \n",
      " operationParameters | {partitionBy -> [\"year\",\"month\"], clusterBy -> [], description -> NULL, isManaged -> true, properties -> {\"delta.enableChangeDataFeed\":\"true\"}} \n",
      " job                 | NULL                                                                                                                                            \n",
      " notebook            | NULL                                                                                                                                            \n",
      " clusterId           | NULL                                                                                                                                            \n",
      " readVersion         | NULL                                                                                                                                            \n",
      " isolationLevel      | Serializable                                                                                                                                    \n",
      " isBlindAppend       | false                                                                                                                                           \n",
      " operationMetrics    | {numFiles -> 51, numOutputRows -> 100, numOutputBytes -> 155518}                                                                                \n",
      " userMetadata        | NULL                                                                                                                                            \n",
      " engineInfo          | Apache-Spark/3.5.3 Delta-Lake/3.2.0                                                                                                             \n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"DESCRIBE HISTORY '{LOCAL_ACCOUNT_TABLE}'\").show(vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c16963-957c-4c5a-b2ee-5496f4a2122d",
   "metadata": {},
   "source": [
    "## As the local catalog is set\n",
    "\n",
    "spark.sql.catalog.local.warehouse\", \"file:///home/baptvit/Documents/github/lakehouse-labs/notebooks/warehouse/delta/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a8ca114-0ef1-491f-8da4-e9331be1daab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:41:49.862684Z",
     "iopub.status.busy": "2025-01-14T18:41:49.862435Z",
     "iopub.status.idle": "2025-01-14T18:41:50.021321Z",
     "shell.execute_reply": "2025-01-14T18:41:50.020982Z",
     "shell.execute_reply.started": "2025-01-14T18:41:49.862661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " version             | 0                                                                                                                                               \n",
      " timestamp           | 2025-01-14 15:41:19                                                                                                                             \n",
      " userId              | NULL                                                                                                                                            \n",
      " userName            | NULL                                                                                                                                            \n",
      " operation           | CREATE OR REPLACE TABLE AS SELECT                                                                                                               \n",
      " operationParameters | {partitionBy -> [\"year\",\"month\"], clusterBy -> [], description -> NULL, isManaged -> true, properties -> {\"delta.enableChangeDataFeed\":\"true\"}} \n",
      " job                 | NULL                                                                                                                                            \n",
      " notebook            | NULL                                                                                                                                            \n",
      " clusterId           | NULL                                                                                                                                            \n",
      " readVersion         | NULL                                                                                                                                            \n",
      " isolationLevel      | Serializable                                                                                                                                    \n",
      " isBlindAppend       | false                                                                                                                                           \n",
      " operationMetrics    | {numFiles -> 51, numOutputRows -> 100, numOutputBytes -> 155518}                                                                                \n",
      " userMetadata        | NULL                                                                                                                                            \n",
      " engineInfo          | Apache-Spark/3.5.3 Delta-Lake/3.2.0                                                                                                             \n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE HISTORY delta.accounts\").show(vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1fa209-da74-4808-a88b-c449c02d9875",
   "metadata": {},
   "source": [
    "## Using CDC and table history to identify the increments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b289ed-bafe-4f6e-b4a9-d5eca562d46c",
   "metadata": {},
   "source": [
    "### Local folder with describe history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01ea5dec-726b-4c76-8f1c-fbcdab128b50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:41:54.001476Z",
     "iopub.status.busy": "2025-01-14T18:41:54.000861Z",
     "iopub.status.idle": "2025-01-14T18:41:54.196742Z",
     "shell.execute_reply": "2025-01-14T18:41:54.196408Z",
     "shell.execute_reply.started": "2025-01-14T18:41:54.001454Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the latest version of the Delta table\n",
    "latest_version = spark.sql(f\"DESCRIBE HISTORY '{LOCAL_ACCOUNT_TABLE}'\") \\\n",
    "    .selectExpr(\"max(version)\") \\\n",
    "    .collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a882e304-1c63-4b94-a3ee-666e7494525d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:41:54.653908Z",
     "iopub.status.busy": "2025-01-14T18:41:54.653630Z",
     "iopub.status.idle": "2025-01-14T18:41:54.657340Z",
     "shell.execute_reply": "2025-01-14T18:41:54.656761Z",
     "shell.execute_reply.started": "2025-01-14T18:41:54.653894Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f51db5-a02d-4b27-891f-126390a66219",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T14:33:11.580564Z",
     "iopub.status.busy": "2025-01-13T14:33:11.580255Z",
     "iopub.status.idle": "2025-01-13T14:33:11.582446Z",
     "shell.execute_reply": "2025-01-13T14:33:11.582105Z",
     "shell.execute_reply.started": "2025-01-13T14:33:11.580552Z"
    }
   },
   "source": [
    "### Reading just the last table version using local catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1166b65f-32ee-42a5-bf28-6f11a96777e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:42:01.989518Z",
     "iopub.status.busy": "2025-01-14T18:42:01.989236Z",
     "iopub.status.idle": "2025-01-14T18:42:02.169830Z",
     "shell.execute_reply": "2025-01-14T18:42:02.169437Z",
     "shell.execute_reply.started": "2025-01-14T18:42:01.989496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query changes for the latest version\n",
    "latest_changes_df = spark.read.format(\"delta\") \\\n",
    "    .option(\"readChangeFeed\", \"true\") \\\n",
    "    .option(\"startingVersion\", latest_version) \\\n",
    "    .load(f\"{LOCAL_ACCOUNT_TABLE}\")\n",
    "\n",
    "latest_changes_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d8159d-9576-4904-b6f2-f41476b57f90",
   "metadata": {},
   "source": [
    "## Creating the upsert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a276bc-ad1d-48d2-bfd8-fe9d8ada8fdd",
   "metadata": {},
   "source": [
    "### Upsert Dataset\n",
    "\n",
    "Editing 4 records and adding new 4 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85f18f8e-f096-44c6-9212-d871cfbf44c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:42:02.618862Z",
     "iopub.status.busy": "2025-01-14T18:42:02.618623Z",
     "iopub.status.idle": "2025-01-14T18:42:02.624465Z",
     "shell.execute_reply": "2025-01-14T18:42:02.624083Z",
     "shell.execute_reply.started": "2025-01-14T18:42:02.618846Z"
    }
   },
   "outputs": [],
   "source": [
    "entries = [\n",
    "    # Existing entries\n",
    "    dataset[2], \n",
    "    dataset[4], \n",
    "    dataset[7],\n",
    "    dataset[11],\n",
    "    # New entries\n",
    "    *generate_dataset(4, seed=1037)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8fc774e-2ded-4a09-a263-c91a5d3aa959",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:42:03.766351Z",
     "iopub.status.busy": "2025-01-14T18:42:03.765866Z",
     "iopub.status.idle": "2025-01-14T18:42:03.769461Z",
     "shell.execute_reply": "2025-01-14T18:42:03.768901Z",
     "shell.execute_reply.started": "2025-01-14T18:42:03.766329Z"
    }
   },
   "outputs": [],
   "source": [
    "for entry in entries:\n",
    "    username = entry['name'].lower().replace(\" \", \".\")\n",
    "    entry['email'] = f\"{username}@domain.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c7541ce-1cec-4dac-b371-db3d11daeed8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:42:04.238304Z",
     "iopub.status.busy": "2025-01-14T18:42:04.237922Z",
     "iopub.status.idle": "2025-01-14T18:42:04.263074Z",
     "shell.execute_reply": "2025-01-14T18:42:04.262527Z",
     "shell.execute_reply.started": "2025-01-14T18:42:04.238286Z"
    }
   },
   "outputs": [],
   "source": [
    "upsert_df = spark.createDataFrame(entries)\\\n",
    "        .withColumn(\"year\", year(col(\"created_at\")))\\\n",
    "        .withColumn(\"month\", month(col(\"created_at\")))\\\n",
    "        .withColumn(\"day\", dayofmonth(col(\"created_at\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34fe4ed2-dd0f-4704-9658-dd6fcb23f88e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:42:04.778618Z",
     "iopub.status.busy": "2025-01-14T18:42:04.778320Z",
     "iopub.status.idle": "2025-01-14T18:42:04.943911Z",
     "shell.execute_reply": "2025-01-14T18:42:04.943569Z",
     "shell.execute_reply.started": "2025-01-14T18:42:04.778593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsert_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7d1480a-c08f-40ae-8e59-75d9fdc4f7b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:42:05.319982Z",
     "iopub.status.busy": "2025-01-14T18:42:05.319667Z",
     "iopub.status.idle": "2025-01-14T18:42:05.327792Z",
     "shell.execute_reply": "2025-01-14T18:42:05.327217Z",
     "shell.execute_reply.started": "2025-01-14T18:42:05.319960Z"
    }
   },
   "outputs": [],
   "source": [
    "upsert_df.createOrReplaceTempView(\"upsert_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af465e53-845a-49e0-ba46-72f24a937791",
   "metadata": {},
   "source": [
    "# Upsert Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06983c86-5b47-45f2-b844-8d0dcf9db13a",
   "metadata": {},
   "source": [
    "## Slowly Changing Dimension (SCD) Type 1\n",
    "\n",
    "In SCD Type 1, the existing records are overwritten with new data when there is a match, and new records are inserted when there is no match. This approach does not preserve historical changes; it simply updates the records with the latest data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5f86e0-aaab-423b-b096-652bb8e7b424",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T14:52:27.927952Z",
     "iopub.status.busy": "2025-01-13T14:52:27.927643Z",
     "iopub.status.idle": "2025-01-13T14:52:27.929987Z",
     "shell.execute_reply": "2025-01-13T14:52:27.929623Z",
     "shell.execute_reply.started": "2025-01-13T14:52:27.927937Z"
    }
   },
   "source": [
    "### Using upsert in SQL like syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75dc232-22af-4601-86e4-353ea04363d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\"\"\"\n",
    "#     MERGE INTO deltalake_raw.accounts AS target\n",
    "#     USING upsert_data AS source ON \n",
    "#         target.id = source.id\n",
    "#     WHEN MATCHED THEN UPDATE SET\n",
    "#         target.country_code = source.country_code,\n",
    "#         target.email = source.email,\n",
    "#         target.name = source.name,\n",
    "#         target.iban = source.iban,\n",
    "#         target.swift = source.swift,\n",
    "#         target.passport = source.passport\n",
    "#     WHEN NOT MATCHED THEN INSERT *\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270b8687-7720-4563-b9a9-ff708cf91769",
   "metadata": {},
   "source": [
    "### Using upsert in python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab33baf1-a166-4bc8-9309-1b1159f554c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:42:30.498560Z",
     "iopub.status.busy": "2025-01-14T18:42:30.498064Z",
     "iopub.status.idle": "2025-01-14T18:42:32.432386Z",
     "shell.execute_reply": "2025-01-14T18:42:32.431978Z",
     "shell.execute_reply.started": "2025-01-14T18:42:30.498538Z"
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Load the Delta table\n",
    "delta_table = DeltaTable.forName(spark, \"delta.accounts\")\n",
    "\n",
    "# Perform the merge operation\n",
    "delta_table.alias(\"target\").merge(\n",
    "    source=upsert_df.alias(\"upsert_data\"),\n",
    "    condition=\"target.id = upsert_data.id\"\n",
    ").whenMatchedUpdate(set={\n",
    "    \"country_code\": \"upsert_data.country_code\",\n",
    "    \"email\": \"upsert_data.email\",\n",
    "    \"name\": \"upsert_data.name\",\n",
    "    \"iban\": \"upsert_data.iban\",\n",
    "    \"swift\": \"upsert_data.swift\",\n",
    "    \"passport\": \"upsert_data.passport\"\n",
    "}).whenNotMatchedInsertAll().execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5bba175-9d4c-4c97-9f2b-c3a6a308bc2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:42:37.270045Z",
     "iopub.status.busy": "2025-01-14T18:42:37.269826Z",
     "iopub.status.idle": "2025-01-14T18:42:37.557952Z",
     "shell.execute_reply": "2025-01-14T18:42:37.557539Z",
     "shell.execute_reply.started": "2025-01-14T18:42:37.270017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " version             | 1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      " timestamp           | 2025-01-14 15:42:32                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      " userId              | NULL                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      " userName            | NULL                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      " operation           | MERGE                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      " operationParameters | {predicate -> [\"(id#2479 = id#2414)\"], matchedPredicates -> [{\"actionType\":\"update\"}], notMatchedPredicates -> [{\"actionType\":\"insert\"}], notMatchedBySourcePredicates -> []}                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      " job                 | NULL                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      " notebook            | NULL                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      " clusterId           | NULL                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      " readVersion         | 0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      " isolationLevel      | Serializable                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
      " isBlindAppend       | false                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      " operationMetrics    | {numTargetRowsCopied -> 4, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 3, numTargetBytesAdded -> 10332, numTargetBytesRemoved -> 9429, numTargetDeletionVectorsAdded -> 0, numTargetRowsMatchedUpdated -> 4, executionTimeMs -> 1707, numTargetRowsInserted -> 4, numTargetRowsMatchedDeleted -> 0, numTargetDeletionVectorsUpdated -> 0, scanTimeMs -> 969, numTargetRowsUpdated -> 4, numOutputRows -> 12, numTargetDeletionVectorsRemoved -> 0, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 3, numSourceRows -> 8, numTargetFilesRemoved -> 3, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 565} \n",
      " userMetadata        | NULL                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      " engineInfo          | Apache-Spark/3.5.3 Delta-Lake/3.2.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      "-RECORD 1-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " version             | 0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      " timestamp           | 2025-01-14 15:41:19                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      " userId              | NULL                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      " userName            | NULL                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      " operation           | CREATE OR REPLACE TABLE AS SELECT                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      " operationParameters | {partitionBy -> [\"year\",\"month\"], clusterBy -> [], description -> NULL, isManaged -> true, properties -> {\"delta.enableChangeDataFeed\":\"true\"}}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
      " job                 | NULL                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      " notebook            | NULL                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      " clusterId           | NULL                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      " readVersion         | NULL                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      " isolationLevel      | Serializable                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
      " isBlindAppend       | false                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      " operationMetrics    | {numFiles -> 51, numOutputRows -> 100, numOutputBytes -> 155518}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
      " userMetadata        | NULL                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      " engineInfo          | Apache-Spark/3.5.3 Delta-Lake/3.2.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE HISTORY delta.accounts\").show(vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61f2513-a6e0-4f81-9586-88bbaa9e0df8",
   "metadata": {},
   "source": [
    "## Delta Metadata using table_changes (Changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8434cb-2b72-44b5-8eb1-a442a2d454a8",
   "metadata": {},
   "source": [
    "### Slowly Changing Dimension (SCD) Type 2\n",
    "\n",
    "Key Characteristics of SCD Type 2:\n",
    "    \n",
    "    1. Preservation of History: SCD Type 2 retains historical changes by creating new records for each change, rather than overwriting existing records.\n",
    "\n",
    "    2. Versioning: Each change is tracked with a version or timestamp, allowing you to see the state of a record at any point in time.\n",
    "\n",
    "    3. Pre- and Post-Images: The update_preimage and update_postimage change types indicate that the table is capturing the state of a record before and after an update, which is a hallmark of SCD Type 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41a7c3e2-dbbe-414a-8067-1c0aec8eddf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:42:54.438852Z",
     "iopub.status.busy": "2025-01-14T18:42:54.438165Z",
     "iopub.status.idle": "2025-01-14T18:42:54.670408Z",
     "shell.execute_reply": "2025-01-14T18:42:54.669947Z",
     "shell.execute_reply.started": "2025-01-14T18:42:54.438829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+---------------------------+----------------------+------------------------------------+----------------+---------+-----------+----+-----+---+----------------+---------------+----------------------+\n",
      "|country_code|created_at|email                      |iban                  |id                                  |name            |passport |swift      |year|month|day|_change_type    |_commit_version|_commit_timestamp     |\n",
      "+------------+----------+---------------------------+----------------------+------------------------------------+----------------+---------+-----------+----+-----+---+----------------+---------------+----------------------+\n",
      "|AR          |2024-12-10|derrick15@example.com      |GB14AYNQ55188150393152|0daad7bc-25b6-4469-8a2f-2ba767f86791|Cassidy Jones MD|595954695|VTHYGBZMNOI|2024|12   |10 |update_preimage |1              |2025-01-14 15:42:32.32|\n",
      "|AR          |2024-12-10|cassidy.jones.md@domain.com|GB14AYNQ55188150393152|0daad7bc-25b6-4469-8a2f-2ba767f86791|Cassidy Jones MD|595954695|VTHYGBZMNOI|2024|12   |10 |update_postimage|1              |2025-01-14 15:42:32.32|\n",
      "|GE          |2024-12-11|tramos@example.com         |GB02LAAF80272115976869|4cbbf121-caae-42aa-8508-3fd99bb2f762|Kara Thomas     |661814813|DULPGBWLTDU|2024|12   |11 |update_preimage |1              |2025-01-14 15:42:32.32|\n",
      "|GE          |2024-12-11|kara.thomas@domain.com     |GB02LAAF80272115976869|4cbbf121-caae-42aa-8508-3fd99bb2f762|Kara Thomas     |661814813|DULPGBWLTDU|2024|12   |11 |update_postimage|1              |2025-01-14 15:42:32.32|\n",
      "|JP          |2024-12-14|anthony.blair@domain.com   |GB63BUEB96211985511216|511d51ba-54be-4f6e-a824-5657fc1eda1b|Anthony Blair   |G42414114|UJRFGBB7P9V|2024|12   |14 |insert          |1              |2025-01-14 15:42:32.32|\n",
      "|AR          |2024-12-16|donaldpierce@example.net   |GB55LFTZ50027083194346|b7e33adb-9bfe-465f-a533-1d57f8d9c9f6|Ann Cruz        |T22953641|HMAQGBCSXE8|2024|12   |16 |update_preimage |1              |2025-01-14 15:42:32.32|\n",
      "|AR          |2024-12-16|ann.cruz@domain.com        |GB55LFTZ50027083194346|b7e33adb-9bfe-465f-a533-1d57f8d9c9f6|Ann Cruz        |T22953641|HMAQGBCSXE8|2024|12   |16 |update_postimage|1              |2025-01-14 15:42:32.32|\n",
      "|FR          |2025-01-05|amber.gomez@domain.com     |GB14JAMN32652852396677|7e1d1d6c-ac3b-478c-b0a0-901515929588|Amber Gomez     |V40815604|OEDJGBV2XYE|2025|1    |5  |insert          |1              |2025-01-14 15:42:32.32|\n",
      "|UK          |2025-01-10|michele99@example.net      |GB83QLKQ49955494203274|eda0dc3f-2296-4859-bdc7-b1c8aa84e5c6|Joseph Arellano |N43772821|VDYQGB92ZCM|2025|1    |10 |update_preimage |1              |2025-01-14 15:42:32.32|\n",
      "|UK          |2025-01-10|joseph.arellano@domain.com |GB83QLKQ49955494203274|eda0dc3f-2296-4859-bdc7-b1c8aa84e5c6|Joseph Arellano |N43772821|VDYQGB92ZCM|2025|1    |10 |update_postimage|1              |2025-01-14 15:42:32.32|\n",
      "|GE          |2024-11-08|david.flynn@domain.com     |GB02WPAU75504619793222|3b07d43d-e15f-4825-9cee-a937fceaeb81|David Flynn     |481064071|MKYOGBA7ENY|2024|11   |8  |insert          |1              |2025-01-14 15:42:32.32|\n",
      "|BR          |2024-11-21|jennifer.lamb@domain.com   |GB77NEUS86176381267948|52c2ae7c-6107-4095-98dc-7d797ebf2b05|Jennifer Lamb   |283291701|DZQUGBI6R85|2024|11   |21 |insert          |1              |2025-01-14 15:42:32.32|\n",
      "+------------+----------+---------------------------+----------------------+------------------------------------+----------------+---------+-----------+----+-----+---+----------------+---------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        *\n",
    "    FROM\n",
    "        table_changes('delta.accounts', 1)\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4fbac1-1c50-4464-bde2-7c0f89cafe5c",
   "metadata": {},
   "source": [
    "### Get only the changes in the last version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "492576c8-bd98-4e5d-b0b8-8998779ca5f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:43:11.673215Z",
     "iopub.status.busy": "2025-01-14T18:43:11.672827Z",
     "iopub.status.idle": "2025-01-14T18:43:11.822128Z",
     "shell.execute_reply": "2025-01-14T18:43:11.821657Z",
     "shell.execute_reply.started": "2025-01-14T18:43:11.673182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+---------------------------+----------------------+------------------------------------+----------------+---------+-----------+----+-----+---+----------------+---------------+----------------------+\n",
      "|country_code|created_at|email                      |iban                  |id                                  |name            |passport |swift      |year|month|day|_change_type    |_commit_version|_commit_timestamp     |\n",
      "+------------+----------+---------------------------+----------------------+------------------------------------+----------------+---------+-----------+----+-----+---+----------------+---------------+----------------------+\n",
      "|AR          |2024-12-10|cassidy.jones.md@domain.com|GB14AYNQ55188150393152|0daad7bc-25b6-4469-8a2f-2ba767f86791|Cassidy Jones MD|595954695|VTHYGBZMNOI|2024|12   |10 |update_postimage|1              |2025-01-14 15:42:32.32|\n",
      "|GE          |2024-12-11|kara.thomas@domain.com     |GB02LAAF80272115976869|4cbbf121-caae-42aa-8508-3fd99bb2f762|Kara Thomas     |661814813|DULPGBWLTDU|2024|12   |11 |update_postimage|1              |2025-01-14 15:42:32.32|\n",
      "|JP          |2024-12-14|anthony.blair@domain.com   |GB63BUEB96211985511216|511d51ba-54be-4f6e-a824-5657fc1eda1b|Anthony Blair   |G42414114|UJRFGBB7P9V|2024|12   |14 |insert          |1              |2025-01-14 15:42:32.32|\n",
      "|AR          |2024-12-16|ann.cruz@domain.com        |GB55LFTZ50027083194346|b7e33adb-9bfe-465f-a533-1d57f8d9c9f6|Ann Cruz        |T22953641|HMAQGBCSXE8|2024|12   |16 |update_postimage|1              |2025-01-14 15:42:32.32|\n",
      "|FR          |2025-01-05|amber.gomez@domain.com     |GB14JAMN32652852396677|7e1d1d6c-ac3b-478c-b0a0-901515929588|Amber Gomez     |V40815604|OEDJGBV2XYE|2025|1    |5  |insert          |1              |2025-01-14 15:42:32.32|\n",
      "|UK          |2025-01-10|joseph.arellano@domain.com |GB83QLKQ49955494203274|eda0dc3f-2296-4859-bdc7-b1c8aa84e5c6|Joseph Arellano |N43772821|VDYQGB92ZCM|2025|1    |10 |update_postimage|1              |2025-01-14 15:42:32.32|\n",
      "|GE          |2024-11-08|david.flynn@domain.com     |GB02WPAU75504619793222|3b07d43d-e15f-4825-9cee-a937fceaeb81|David Flynn     |481064071|MKYOGBA7ENY|2024|11   |8  |insert          |1              |2025-01-14 15:42:32.32|\n",
      "|BR          |2024-11-21|jennifer.lamb@domain.com   |GB77NEUS86176381267948|52c2ae7c-6107-4095-98dc-7d797ebf2b05|Jennifer Lamb   |283291701|DZQUGBI6R85|2024|11   |21 |insert          |1              |2025-01-14 15:42:32.32|\n",
      "+------------+----------+---------------------------+----------------------+------------------------------------+----------------+---------+-----------+----+-----+---+----------------+---------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        *\n",
    "    FROM\n",
    "        table_changes('delta.accounts', 1)\n",
    "    WHERE\n",
    "        _change_type IN ('insert', 'update_postimage')\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0750d4-659f-4d6a-adcd-359f6bca3395",
   "metadata": {},
   "source": [
    "### Version 0 of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96148f31-f7e3-4f2f-9ecd-759bad1ef71c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:43:25.533108Z",
     "iopub.status.busy": "2025-01-14T18:43:25.532488Z",
     "iopub.status.idle": "2025-01-14T18:43:26.519744Z",
     "shell.execute_reply": "2025-01-14T18:43:26.519302Z",
     "shell.execute_reply.started": "2025-01-14T18:43:25.533084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+---------------------+----------------------+------------------------------------+----------------+---------+-----------+----+-----+---+\n",
      "|country_code|created_at|email                |iban                  |id                                  |name            |passport |swift      |year|month|day|\n",
      "+------------+----------+---------------------+----------------------+------------------------------------+----------------+---------+-----------+----+-----+---+\n",
      "|AR          |2024-12-10|derrick15@example.com|GB14AYNQ55188150393152|0daad7bc-25b6-4469-8a2f-2ba767f86791|Cassidy Jones MD|595954695|VTHYGBZMNOI|2024|12   |10 |\n",
      "+------------+----------+---------------------+----------------------+------------------------------------+----------------+---------+-----------+----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        *\n",
    "    FROM\n",
    "        delta.accounts version as of 0\n",
    "    WHERE\n",
    "        id = '0daad7bc-25b6-4469-8a2f-2ba767f86791'\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd6d4de-2349-4768-be67-e8cb132acb88",
   "metadata": {},
   "source": [
    "### Version 1 of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9320b58e-bb12-4d07-964e-2d0af2acce6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T18:43:26.520434Z",
     "iopub.status.busy": "2025-01-14T18:43:26.520317Z",
     "iopub.status.idle": "2025-01-14T18:43:27.081321Z",
     "shell.execute_reply": "2025-01-14T18:43:27.080998Z",
     "shell.execute_reply.started": "2025-01-14T18:43:26.520423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+---------------------------+----------------------+------------------------------------+----------------+---------+-----------+----+-----+---+\n",
      "|country_code|created_at|email                      |iban                  |id                                  |name            |passport |swift      |year|month|day|\n",
      "+------------+----------+---------------------------+----------------------+------------------------------------+----------------+---------+-----------+----+-----+---+\n",
      "|AR          |2024-12-10|cassidy.jones.md@domain.com|GB14AYNQ55188150393152|0daad7bc-25b6-4469-8a2f-2ba767f86791|Cassidy Jones MD|595954695|VTHYGBZMNOI|2024|12   |10 |\n",
      "+------------+----------+---------------------------+----------------------+------------------------------------+----------------+---------+-----------+----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        *\n",
    "    FROM\n",
    "        delta.accounts version as of 1\n",
    "    WHERE\n",
    "        id = '0daad7bc-25b6-4469-8a2f-2ba767f86791'\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bbda5e-4200-478c-a570-917089b95fd6",
   "metadata": {},
   "source": [
    "## TODO: Optimaze commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7705bd-f635-4269-b220-28ab2d75b1eb",
   "metadata": {},
   "source": [
    "## TODO: Liquid clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0a7ab4-5633-4b6e-8215-3f8574f187a6",
   "metadata": {},
   "source": [
    "## TODO: Miscellaneous on delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5020db-d5aa-4b9a-abdc-7af4270a2e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
