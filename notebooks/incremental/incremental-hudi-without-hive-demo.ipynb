{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4da4cb3-cbdd-4a27-9186-04a783857341",
   "metadata": {},
   "source": [
    "# POC: Incremental reads on Hudi without hive metastore\n",
    "\n",
    "Using local metastore with incremental feactures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d13cf6d-9faa-44f0-87b8-31f777821f9d",
   "metadata": {},
   "source": [
    "# Use cases\n",
    "Change Data Feed is not enabled by default. The following use cases should drive when you enable the change data feed.\n",
    "\n",
    "1. Silver and Gold tables: Improve Delta performance by processing only row-level changes following initial MERGE, UPDATE, or DELETE operations to accelerate and simplify ETL and ELT operations.\n",
    "\n",
    "2. Transmit changes: Send a change data feed to downstream systems such as Kafka or RDBMS that can use it to incrementally process in later stages of data pipelines.\n",
    "\n",
    "3. Audit trail table: Capture the change data feed as a Delta table provides perpetual storage and efficient query capability to see all changes over time, including when deletes occur and what updates were made.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25d1b72-0c51-4be3-b987-a6cca3d70c56",
   "metadata": {},
   "source": [
    "# Known constrains:\n",
    "\n",
    "- Versions lower than 0.15.0 must be aware of possible commits retantion policies. By default hudi keeps last **10 commits** of a table. [reference](https://hudi.apache.org/docs/0.15.0/hoodie_cleaner/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07664dfd-9c6f-473a-b322-b311564ee3f1",
   "metadata": {},
   "source": [
    "## Before run\n",
    "\n",
    "Checks if spark 3.5.3 and Hadoop are install\n",
    "also the pyspark>=3.5.3 libraries.\n",
    "\n",
    "Remove if existis the /warehouse/ folder in this direcory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91d07b1d-2be6-4b5d-bbbb-00270bba8367",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T15:23:17.372385Z",
     "iopub.status.busy": "2025-01-14T15:23:17.372176Z",
     "iopub.status.idle": "2025-01-14T15:23:17.417669Z",
     "shell.execute_reply": "2025-01-14T15:23:17.417323Z",
     "shell.execute_reply.started": "2025-01-14T15:23:17.372361Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, year, month, dayofmonth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40940756-17f4-44f7-ade4-8cc6a448538a",
   "metadata": {},
   "source": [
    "### Spark Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4d262d6-90c2-40f7-b4db-5ed3ec455956",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T15:23:22.343057Z",
     "iopub.status.busy": "2025-01-14T15:23:22.342857Z",
     "iopub.status.idle": "2025-01-14T15:23:22.345118Z",
     "shell.execute_reply": "2025-01-14T15:23:22.344855Z",
     "shell.execute_reply.started": "2025-01-14T15:23:22.343042Z"
    }
   },
   "outputs": [],
   "source": [
    "spark_jar_packages = \",\".join([\n",
    "    #\"org.apache.hudi:hudi-spark3.5-bundle_2.12:0.15.0\",\n",
    "    \"org.apache.hudi:hudi-spark3.5-bundle_2.12:1.0.0\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62dd970b-a205-4b9e-84e3-5cd395dd33a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T15:23:22.544663Z",
     "iopub.status.busy": "2025-01-14T15:23:22.544478Z",
     "iopub.status.idle": "2025-01-14T15:23:22.546701Z",
     "shell.execute_reply": "2025-01-14T15:23:22.546412Z",
     "shell.execute_reply.started": "2025-01-14T15:23:22.544652Z"
    }
   },
   "outputs": [],
   "source": [
    "LOCAL_WAREHOUSE_CATALOG = \"file:///home/baptvit/Documents/github/lakehouse-labs/notebooks/warehouse/hudi/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d417510-85ba-4981-a1c1-4b949381e70a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T15:23:22.904117Z",
     "iopub.status.busy": "2025-01-14T15:23:22.903839Z",
     "iopub.status.idle": "2025-01-14T15:23:25.269830Z",
     "shell.execute_reply": "2025-01-14T15:23:25.269427Z",
     "shell.execute_reply.started": "2025-01-14T15:23:22.904097Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/14 12:23:23 WARN Utils: Your hostname, baptvit resolves to a loopback address: 127.0.1.1; using 192.168.2.129 instead (on interface wlp4s0)\n",
      "25/01/14 12:23:23 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Ivy Default Cache set to: /home/baptvit/.ivy2/cache\n",
      "The jars for the packages stored in: /home/baptvit/.ivy2/jars\n",
      "org.apache.hudi#hudi-spark3.5-bundle_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-7ec19967-fd59-4860-8428-6313ebfd160c;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound org.apache.hudi#hudi-spark3.5-bundle_2.12;1.0.0 in central\n",
      "\tfound org.apache.hive#hive-storage-api;2.8.1 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.36 in central\n",
      ":: resolution report :: resolve 122ms :: artifacts dl 4ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.hive#hive-storage-api;2.8.1 from central in [default]\n",
      "\torg.apache.hudi#hudi-spark3.5-bundle_2.12;1.0.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.36 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-7ec19967-fd59-4860-8428-6313ebfd160c\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/3ms)\n",
      "25/01/14 12:23:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .master(\"local[*]\")\n",
    "    .appName(\"hudi-local-playground\")\n",
    "    .config(\"spark.jars.packages\", spark_jar_packages)\n",
    "\n",
    "    # Hudi-Hive Integration\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "    .config(\"spark.kryo.registrator\", \"org.apache.spark.HoodieSparkKryoRegistrar\")\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.spark.sql.hudi.HoodieSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.hudi.catalog.HoodieCatalog\")\n",
    "    \n",
    "    .config(\"spark.sql.catalog.local.type\", \"hadoop\")   # Use Hadoop catalog\n",
    "    .config(\"spark.sql.warehouse.dir\", LOCAL_WAREHOUSE_CATALOG)   # Path to store metadata\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9789e3b-bdeb-42f9-9910-6a5a1d939ee6",
   "metadata": {},
   "source": [
    "## Creating a fake database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efa07f69-02fe-4deb-a14c-59de36b3c08b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T15:23:36.198144Z",
     "iopub.status.busy": "2025-01-14T15:23:36.197727Z",
     "iopub.status.idle": "2025-01-14T15:23:36.313556Z",
     "shell.execute_reply": "2025-01-14T15:23:36.313197Z",
     "shell.execute_reply.started": "2025-01-14T15:23:36.198114Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "def generate_entry(faker: Faker, country_codes: list):\n",
    "    return {\n",
    "        \"id\": faker.unique.uuid4(),\n",
    "        \"name\":  faker.name(),\n",
    "        \"email\": faker.email(),\n",
    "        \"passport\": faker.passport_number(),\n",
    "        \"country_code\": random.choice(country_codes),\n",
    "        \"iban\": faker.iban(),\n",
    "        \"swift\": faker.swift11(),\n",
    "        \"created_at\": faker.past_date(start_date='-90d').strftime('%Y-%m-%d')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53c245a4-9ace-4bf1-9897-4a8d186ac5f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T15:23:36.374504Z",
     "iopub.status.busy": "2025-01-14T15:23:36.374238Z",
     "iopub.status.idle": "2025-01-14T15:23:36.377740Z",
     "shell.execute_reply": "2025-01-14T15:23:36.377432Z",
     "shell.execute_reply.started": "2025-01-14T15:23:36.374480Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_dataset(num: int, seed: int):\n",
    "    country_codes = ['US', 'CA', 'JP', 'KR', 'FR', 'GE', 'UK', 'BR', 'AR']\n",
    "    Faker.seed(seed)\n",
    "    faker = Faker()\n",
    "    return [generate_entry(faker, country_codes) for _ in range(num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "599e5cd7-d544-4b4e-9b89-09b483fef953",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T15:23:36.623543Z",
     "iopub.status.busy": "2025-01-14T15:23:36.623347Z",
     "iopub.status.idle": "2025-01-14T15:23:36.672523Z",
     "shell.execute_reply": "2025-01-14T15:23:36.672206Z",
     "shell.execute_reply.started": "2025-01-14T15:23:36.623530Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = generate_dataset(num=100, seed=739)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74e985a4-3ccc-4b2b-a30f-ee40107bc10e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T15:23:37.297196Z",
     "iopub.status.busy": "2025-01-14T15:23:37.297004Z",
     "iopub.status.idle": "2025-01-14T15:23:38.188921Z",
     "shell.execute_reply": "2025-01-14T15:23:38.188573Z",
     "shell.execute_reply.started": "2025-01-14T15:23:37.297183Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/14 12:23:38 WARN DFSPropertiesConfiguration: Properties file file:/etc/hudi/conf/hudi-defaults.conf not found. Ignoring to load props file\n",
      "25/01/14 12:23:38 WARN DFSPropertiesConfiguration: Cannot find HUDI_CONF_DIR, please set it as the dir of hudi-defaults.conf\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(dataset)\\\n",
    "        .withColumn(\"year\", year(col(\"created_at\")))\\\n",
    "        .withColumn(\"month\", month(col(\"created_at\")))\\\n",
    "        .withColumn(\"day\", dayofmonth(col(\"created_at\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c77d342-a61b-4c88-babe-caccb6b27576",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T15:23:38.198003Z",
     "iopub.status.busy": "2025-01-14T15:23:38.197847Z",
     "iopub.status.idle": "2025-01-14T15:23:39.712026Z",
     "shell.execute_reply": "2025-01-14T15:23:39.711673Z",
     "shell.execute_reply.started": "2025-01-14T15:23:38.197992Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43f08395-5e99-4dde-a0c1-8c466cf2dca4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T15:23:39.712913Z",
     "iopub.status.busy": "2025-01-14T15:23:39.712666Z",
     "iopub.status.idle": "2025-01-14T15:23:40.322280Z",
     "shell.execute_reply": "2025-01-14T15:23:40.321850Z",
     "shell.execute_reply.started": "2025-01-14T15:23:39.712897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+--------------------+--------------------+--------------------+-----------+---------+-----------+----+-----+---+\n",
      "|country_code|created_at|               email|                iban|                  id|       name| passport|      swift|year|month|day|\n",
      "+------------+----------+--------------------+--------------------+--------------------+-----------+---------+-----------+----+-----+---+\n",
      "|          AR|2024-10-21|powelljason@examp...|GB77AKMZ560580635...|5a424412-b127-4f8...|Cody Taylor|895549199|INSEGB5PR6S|2024|   10| 21|\n",
      "+------------+----------+--------------------+--------------------+--------------------+-----------+---------+-----------+----+-----+---+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/14 12:23:41 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feb1ff2-6a95-4e4f-8cce-443d04779f9f",
   "metadata": {},
   "source": [
    "## Save using the default database\n",
    "\n",
    "Hudi trancks automatically the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10077db9-45dc-4af0-8439-7f204f7fba50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T15:23:48.005915Z",
     "iopub.status.busy": "2025-01-14T15:23:48.005517Z",
     "iopub.status.idle": "2025-01-14T15:23:48.112686Z",
     "shell.execute_reply": "2025-01-14T15:23:48.112271Z",
     "shell.execute_reply.started": "2025-01-14T15:23:48.005891Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    CREATE DATABASE IF NOT EXISTS hudi;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be022e3c-0ef9-466e-8bcf-08c39ad97783",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T15:23:48.227450Z",
     "iopub.status.busy": "2025-01-14T15:23:48.227230Z",
     "iopub.status.idle": "2025-01-14T15:23:51.838932Z",
     "shell.execute_reply": "2025-01-14T15:23:51.838547Z",
     "shell.execute_reply.started": "2025-01-14T15:23:48.227435Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/14 12:23:49 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-hbase.properties,hadoop-metrics2.properties\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# WARNING: Unable to get Instrumentation. Dynamic Attach failed. You may add this JAR as -javaagent manually, or supply -Djdk.attach.allowAttachSelf\n",
      "# WARNING: Unable to attach Serviceability Agent. Unable to attach even with module exceptions: [org.apache.hudi.org.openjdk.jol.vm.sa.SASupportException: Sense failed., org.apache.hudi.org.openjdk.jol.vm.sa.SASupportException: Sense failed., org.apache.hudi.org.openjdk.jol.vm.sa.SASupportException: Sense failed.]\n"
     ]
    }
   ],
   "source": [
    "df.write.format(\"hudi\") \\\n",
    "    .option(\"hoodie.database.name\", \"hudi\") \\\n",
    "    .option(\"hoodie.table.name\", \"accounts_1\") \\\n",
    "    .option(\"hoodie.datasource.write.recordkey.field\", \"id\") \\\n",
    "    .option(\"hoodie.datasource.write.precombine.field\", \"created_at\") \\\n",
    "    .option(\"hoodie.datasource.write.table.type\", \"COPY_ON_WRITE\") \\\n",
    "    .option(\"hoodie.datasource.write.operation\", \"upsert\") \\\n",
    "    .option(\"hoodie.datasource.hive_sync.partition_fields\", \"year,month\") \\\n",
    "    .option(\"hoodie.datasource.hive_sync.partition_extractor_class\", \"org.apache.hudi.hive.MultiPartKeysValueExtractor\") \\\n",
    "    .option(\"hoodie.datasource.write.hive_style_partitioning\",\"true\") \\\n",
    "    .partitionBy(\"year\", \"month\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .save(\"file:///home/baptvit/Documents/github/lakehouse-labs/notebooks/warehouse/hudi/hudi.db/accounts_1\") ## hudi needs the base full path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce71b2e-424d-482e-852f-4d2a8f707541",
   "metadata": {},
   "source": [
    "## Reading from local direct from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1c6d7d-fb8a-4d24-9246-251bb6605708",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_ACCOUNT_TABLE = LOCAL_WAREHOUSE_CATALOG + \"hudi_db.db/accounts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec69fa57-0864-4cbc-858b-86002697d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# providing a starting version\n",
    "df_read = spark.read.format(\"hudi\") \\\n",
    "  .load(LOCAL_ACCOUNT_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b199c332-f0fd-4835-a64f-09e54fd381b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6349cb-7e07-4fa9-953b-45c54e7ad289",
   "metadata": {},
   "source": [
    "## Reading the table history from local folder\n",
    "\n",
    "Local folder and spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfe3f71-643d-484b-b606-f275494d6cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    CREATE DATABASE IF NOT EXISTS hudi_db;\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2174cd8-7e0f-4f7e-93e5-ffb8923c2345",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\n",
    "    f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS hudi_db.accounts\n",
    "        USING hudi\n",
    "        OPTIONS (\n",
    "          path = '{LOCAL_ACCOUNT_TABLE}'\n",
    "        );\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e709c2-c898-4d1a-bae4-f835c6e06665",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    call show_commits (\n",
    "        table => 'hudi_db.accounts',\n",
    "        from_commit => '10'\n",
    "    )    \n",
    "\"\"\").show(vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4708cca-8b35-4a86-b7ff-ec0f79a8397c",
   "metadata": {},
   "source": [
    "## Using CDC and table history to identify the increments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ca7055-421f-45db-8acb-b8149e76445e",
   "metadata": {},
   "source": [
    "### Local folder with show_commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1beaa9-3ced-4cb6-b0f1-978b9b080650",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_commig_time = spark.sql(\"\"\"\n",
    "    call show_commits (\n",
    "        table => 'hudi_db.accounts',\n",
    "        from_commit => '0'\n",
    "    )    \n",
    "\"\"\").collect()[0][0]\n",
    "\n",
    "last_commig_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7a110a-1295-48c0-9a8d-08a63936ec92",
   "metadata": {},
   "source": [
    "### Reading just the last table version using local catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10aaddd-3f26-487d-8aa5-872c50c6da33",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.format(\"hudi\") \\\n",
    "    .option(\"hoodie.datasource.query.type\", \"incremental\") \\\n",
    "    .option(\"hoodie.datasource.read.begin.instanttime\", last_commig_time) \\\n",
    "    .load(LOCAL_ACCOUNT_TABLE).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50584e4a-1a9f-4e87-b229-f7ef5a390dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.format(\"hudi\") \\\n",
    "    .option(\"hoodie.datasource.query.type\", \"incremental\") \\\n",
    "    .option(\"hoodie.datasource.read.begin.instanttime\", last_commig_time) \\\n",
    "    .load(LOCAL_ACCOUNT_TABLE).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6741eb33-75a2-439a-a1fd-f99a400e29f2",
   "metadata": {},
   "source": [
    "## Creating the upsert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88b93cc-3d96-4b18-814f-8325e2177abd",
   "metadata": {},
   "source": [
    "### Upsert Dataset\n",
    "\n",
    "Editing 4 records and adding new 4 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16cd012-59a0-49c1-8219-a29bab71659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = [\n",
    "    # Existing entries\n",
    "    dataset[2], \n",
    "    dataset[4], \n",
    "    dataset[7],\n",
    "    dataset[11],\n",
    "    # New entries\n",
    "    *generate_dataset(4, seed=1037)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22d6316-d4dc-44b8-839d-899558c86523",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in entries:\n",
    "    username = entry['name'].lower().replace(\" \", \".\")\n",
    "    entry['email'] = f\"{username}@domain.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22fbc81-0bcd-4e97-bdff-eb3e448e18b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsert_df = spark.createDataFrame(entries)\\\n",
    "        .withColumn(\"year\", year(col(\"created_at\")))\\\n",
    "        .withColumn(\"month\", month(col(\"created_at\")))\\\n",
    "        .withColumn(\"day\", dayofmonth(col(\"created_at\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3e400a-8c87-49a5-8d14-aeb5b355c7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsert_df.show(8, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8161f9aa-5f67-4a23-af72-66eeb628588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsert_df.createOrReplaceTempView(\"upsert_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e7a87c-53cc-4f9b-98db-98ab23d9ef83",
   "metadata": {},
   "source": [
    "# Upsert Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5437a646-2522-42f2-a3cb-f42f648aa45a",
   "metadata": {},
   "source": [
    "## Slowly Changing Dimension (SCD) Type 1\n",
    "\n",
    "In SCD Type 1, the existing records are overwritten with new data when there is a match, and new records are inserted when there is no match. This approach does not preserve historical changes; it simply updates the records with the latest data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4335a7-80ef-4f39-8009-5cab3bee6d4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T15:25:57.417128Z",
     "iopub.status.busy": "2025-01-13T15:25:57.416460Z",
     "iopub.status.idle": "2025-01-13T15:25:57.420418Z",
     "shell.execute_reply": "2025-01-13T15:25:57.420055Z",
     "shell.execute_reply.started": "2025-01-13T15:25:57.417104Z"
    }
   },
   "source": [
    "HUDI Achive upsert SCD by default enabling the **\"hoodie.datasource.write.operation\", \"upsert\" and .mode(\"append\")**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b405d198-3732-41b7-8877-3357689ce574",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsert_df.write.format(\"hudi\") \\\n",
    "    .option(\"hoodie.database.name\", \"hudi_db\") \\\n",
    "    .option(\"hoodie.table.name\", \"accounts\") \\\n",
    "    .option(\"hoodie.datasource.write.recordkey.field\", \"id\") \\\n",
    "    .option(\"hoodie.datasource.write.precombine.field\", \"created_at\") \\\n",
    "    .option(\"hoodie.datasource.write.table.type\", \"COPY_ON_WRITE\") \\\n",
    "    .option(\"hoodie.datasource.write.operation\", \"upsert\") \\\n",
    "    .option(\"hoodie.datasource.hive_sync.partition_fields\", \"year,month\") \\\n",
    "    .option(\"hoodie.datasource.hive_sync.partition_extractor_class\", \"org.apache.hudi.hive.MultiPartKeysValueExtractor\") \\\n",
    "    .option(\"hoodie.datasource.write.hive_style_partitioning\",\"true\") \\\n",
    "    .partitionBy(\"year\", \"month\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .save(\"file:///home/baptvit/Documents/github/lakehouse-labs/notebooks/warehouse/hudi/hudi_db.db/accounts\") ## hudi needs the base full path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d018fef2-aeae-4162-bbd1-d4ff9ce27054",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\n",
    "    f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS hudi_db.accounts\n",
    "        USING hudi\n",
    "        OPTIONS (\n",
    "          path = '{LOCAL_ACCOUNT_TABLE}'\n",
    "        );\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfdd6e7-3fbf-4c47-bd30-f2d027bf2897",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    call show_commits (\n",
    "        table => 'hudi_db.accounts',\n",
    "        from_commit => '2'\n",
    "    )    \n",
    "\"\"\").show(vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874bda21-6550-4597-a8b9-0d017ac9acd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T15:32:13.681219Z",
     "iopub.status.busy": "2025-01-13T15:32:13.680689Z",
     "iopub.status.idle": "2025-01-13T15:32:13.683497Z",
     "shell.execute_reply": "2025-01-13T15:32:13.683068Z",
     "shell.execute_reply.started": "2025-01-13T15:32:13.681197Z"
    }
   },
   "source": [
    "### Reading the last changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37a34b3-a375-43bf-9ad5-6e7c5c510e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_commig_time = spark.sql(\"\"\"\n",
    "    call show_commits (\n",
    "        table => 'hudi_db.accounts',\n",
    "        from_commit => '0'\n",
    "    )    \n",
    "\"\"\").collect()[0][0]\n",
    "\n",
    "last_commig_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6000ff5-b25c-4c85-9d33-616e128cfd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.format(\"hudi\") \\\n",
    "    .option(\"hoodie.datasource.query.type\", \"incremental\") \\\n",
    "    .option(\"hoodie.datasource.read.begin.instanttime\", last_commig_time) \\\n",
    "    .load(LOCAL_ACCOUNT_TABLE).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56295003-114b-483d-ac9f-83cba3af005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.format(\"hudi\") \\\n",
    "    .option(\"hoodie.datasource.query.type\", \"incremental\") \\\n",
    "    .option(\"hoodie.datasource.read.begin.instanttime\", last_commig_time) \\\n",
    "    .load(LOCAL_ACCOUNT_TABLE).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8ba405-b963-4029-8aa6-5aa8e88a840a",
   "metadata": {},
   "source": [
    "## TODO: Optimaze commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0858f37-8b40-4abd-bf63-773403d2374a",
   "metadata": {},
   "source": [
    "## TODO: Miscellaneous on Hudi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e62f2bc-c05d-42fb-a309-dab810c24b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782c6528-88ef-4520-8966-801413745208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c606aaee-0f20-467b-833c-6df2f9b04f53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
